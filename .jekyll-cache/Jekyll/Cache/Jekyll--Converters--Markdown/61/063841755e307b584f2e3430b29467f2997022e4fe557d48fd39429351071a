I"w!<h1 id="research">Research</h1>

<p><img src="http://localhost:4000/images/respic/signal_data_AI.png" alt="" style="width: 350px; float: left; margin: 0px 10px" />
<br />
Our overarching goal is to broaden the understanding of sensory interactions from a science and engineering perspective, by analyzing the associated signals. We utilize critical thinking, systematic experimentation, and in depth analysis, enabling us address questions we find most interesting.
<!-- This direction of research is possible thanks also to Neeraj's broad background with different research themes: speech signal modeling and audio signal processing (at IISc), understanding speech perception using behavioral and neural signals (at CMU), sound-based respiratory health diagnosis (at IISc), and spatial audio cognition (at Fraunhofer IIS). --></p>

<p>Here are some themes that we currently work on:</p>

<p><strong>Modeling sensory signal processing</strong><br />
Our sensory system is operating 24x7, and is an evolutionary engineering marvel. We intend to understand how different sensory systems process signals. This process is more broadly termed as mechano-electro-transduction. Computationally modeling this can provide alternative methods for sampling and representation of continuous-time signals. One topic which we have carved out from this interest is “information-rich’’ sampling of non-stationary signals. Here, the goal is to <em>sample not for</em> reconstruction of the complete signal <em>but for</em> reconstruction of the information of interest. Our initial work in this direction has proposed methods such as signal dependent sampling <a href="https://ieeexplore.ieee.org/abstract/document/6288659">Ref</a>, <a href="https://ieeexplore.ieee.org/abstract/document/6983916">Ref</a>, and extrema-triggered sampling of time-varying signals for instantaneous frequency estimation <a href="https://www.sciencedirect.com/science/article/pii/S0165168415001383">Ref</a>.<br />
<em>Keywords: time-series analysis, information theory, sparse signal recovery, compressive sensing, time-frequency analysis, physical and neural processes in sensory systems, signal representations</em></p>

<p><strong>Spoken conversation analysis</strong><br />
Spoken communication enables us to share thoughts, learn and create knowledge. Often we spend our day immersed in <em>listening to</em> or <em>speaking in</em> a conversation. Some conversations are quick and some <em>go on and on</em>, some start gradually and some end abruptly. Some conversations have stayed in our memory for quite some time. Our goal in this work is to explore spoken conversations by capturing and analyzing the speech, facial, breathing, heart and pupil signals of the participating individuals. This is a long-term effort involving building and testing of several hypotheses, and gaining scientific insights into this amazing form of information transfer used by humans. Strength permitting, we also will look forward to analyze this aspect in bird (and animal) communication.<br />
<em>Keywords: real-time multi-channel data acquisition and synchronization, signal processing, machine learning and NNs, psychology-based experiment design, perception and human cognition</em></p>

<p><strong>Audio-based brain-computer interfacing</strong><br />
Since 2013, several EEG data decoding studies have demonstrated correlation between the attended audio signal and the corresponding brain activity captured using EEG. In a recent study, we corroborate this evidence <a href="https://www.cl.uzh.ch/dam/jcr:e4b2bbe9-2648-4224-8a18-439ba0ad0ebd/bookVoiceID_final.pdf#page=23">Ref</a> and add new insights. We are looking forward to scale up this effort and design audio-based BCIs.<br />
<em>Keywords: EEG signal capture and analysis, signal processing, machine learning, audio processing</em></p>

<p><strong>Understanding audio cognition using behavioral experiments</strong><br />
Unlike neuroimaging experiments like EEG and fMRI, behavioral experiments are designed to capture simple behavioral responses such as button press, reaction time, etc. during a live experiment. Interestingly, these simple responses when carefully captured can be analyzed to understand human cognition. We have explored analyzing aspects such as talker perception <a href="https://asa.scitation.org/doi/full/10.1121/1.5084044">Ref1</a>, impact of language on talker perception <a href="https://asa.scitation.org/doi/full/10.1121/10.0002462">Ref2</a>, and currently ongoing, spatial cognition. We look forward to continue learning from this direction of work and translate our findings to make AI algorithms.<br />
<em>Keywords: psychology and cognitive sciences, vision and audition, data science and inferential statistics, AI</em></p>

<p><strong>Data analysis for human healthcare</strong><br />
Do you recall a doctor listening to body sounds using a stethoscope? The art of listening to body sounds is referred to as <em>auscultation</em> and dates back to the 1820s. Our goal is to further the information extraction from body sounds using signal processing and machine learning. The goal is to design remote, cost-effective, and scalable disease screening methodologies. In a recent work, we pursued analysis of respiratory sounds such as breathing, cough and speech collected during the pandemic from individuals with and without COVID-19 <a href="http://eprints.iisc.ac.in/67641/1/coswara-2020-4811-4815.pdf">Ref</a>, <a href="https://www.sciencedirect.com/science/article/pii/S0885230821001157">Ref</a>.<br />
<em>Keywords: time-series analysis, signal processing, audio signal processing, machine learning and NNs, inferential statistics, full stack web development, biosciences</em></p>

<p><strong>Data analysis for climate sciences</strong><br />
The cacophony of sounds in a forest draws contributions from many different species, natural phenomena such as wind, rain, and thunder, and man-made vehicles and machines. Building on this observation, we intend to design ways to monitor forest’s response to changing weather and climate conditions, allowing prediction of adversities. This is a long-term effort involving testing of several hypothesis and solving multiple sub-problems.<br />
<em>Keywords: wildlife sensor design and deployment, data analysis, signal processing and machine learning, ecological sciences, full stack web development</em></p>

<p><strong>Exploratory data analysis and visualization</strong><br />
Data science, being an interdisciplinary field, brings challenges and opportunities for designing creative ways to visualize data. Sometimes a good visualization can highlight hidden patterns in data and light up new ideas for solving a problem. We recognize this talent and try pulling data from various sources to illustrate some interesting patterns.<br />
<em>Keywords: visualization, sonification, animating data science and AI concepts, linear algebra, full stack web development</em></p>

<!-- ![](http://localhost:4000/images/respic/SmartTip.png){: style="width: 250px; float: left; margin: 0px  10px"}
One of the  projects back from my job-proposal is to develop nanofabricated STM tips. The idea behind these “smart tips” is to use the technologies that were developed over decades in nanofabrication and make them available for scanning probes by using a nano-device instead of the traditional STM tungsten tip. One gains the flexibility of using different functionalities that are known from the fields of nanofabrication and mesoscopic physics. We are collaborating with the group Simon Groeblacher at TU Delft to realize this concept, benefitting from their unparalleled micro/nano fabrication know how.  A prototype of a smart tip is shown to the left. See publications in Microsyst Nanoeng, Nanotechnology, and PRB. -->

<!-- **Ultra-stable SI-STM instrument.**  ![](http://localhost:4000/images/respic/STMHead.png){: style="width: 250px; float: right; margin: 0px 10px"}
For SI-STM, having the most stable STM head is key. We have used finite element simulations, good choices in material science, and craftsmanship to build the most stable STM head in the world, to our knowledge. See publication in RSI. -->

<!-- ![](http://localhost:4000/images/respic/SciPost.png){: style="width: 70%; float: center; margin: 0px"} -->

<h4 id="-and-more-as-we-continue-to-learn-and-do">… and more as we continue to learn and do.</h4>

<p><img src="http://localhost:4000/images/respic/ai_mind.png" alt="" style="width: 250px; float: center; margin: 0px 10px" /></p>

:ET